# Bayesian data analysis tools for the Holmes neutrino mass experiment
Many of the examples shown in the thesis can be reproduced using the Jupyter Notebooks collected in [baynes](https://github.com/cryomib/baynes).
## Abstract:

Measuring the absolute neutrino mass scale is one of the most challenging experimental endeavors in contemporary physics. Although neutrino flavor oscillations prove that at least two neutrinos have a non-zero mass, directly determining their extremely small values still requires advancing current detector technologies and performance. Model-independent methods for this measurement rely on energy and momentum conservation, analyzing the energy spectrum of beta decay or electron capture isotopes. The Holmes experiment, under development since 2014 at the cryogenic laboratory of the University of Milano-Bicocca, aims to provide a calorimetric measurement of the electron neutrino mass by studying the electron capture decay of <sup>163</sup>Ho. In a calorimetric experiment, the radioactive isotope is embedded in an absorber connected to a very sensitive thermometer, measuring all the energy of the decay except for that carried away by the neutrino. The shape of the resulting calorimetric energy spectrum near the endpoint depends on the value of the electron neutrino mass.

This work outlines the development of Bayesian data analysis routines for the Holmes experiment using Stan, a specialized Hamiltonian Monte Carlo toolkit and probabilistic programming language. The primary objective is to design and fit statistical models to characterize the calorimetric spectrum of <sup>163</sup>Ho and estimate the neutrino mass from its endpoint. In parallel with the software development, I have taken part in the experimental activities of the group, from the hardware setup to the first measurement campaign involving detectors implanted with <sup>163</sup>Ho.

To accumulate the required statistics while maintaining an excellent energy resolution and detector time response,
Holmes uses arrays of microcalorimeters based on Transition Edge Sensors (TES). Each detector in the array consists of a
TES connected to a gold absorber implanted with <sup>163</sup>Ho. The first chapter details the physical principles behind
these detectors and how the TESs in an array can be read simultaneously using Microwave Multiplexing techniques. The chapter concludes with a description of the current experimental setup.

Chapter 2 provides an introduction to Bayesian data analysis. Bayesian statistics offer a powerful framework for the estimation of uncertainty, describing unknown quantities such as the parameters of a model with probability distributions. In the Bayesian paradigm, inference is carried out by using the observed data to update the initial knowledge about a parameter, which is represented by a prior distribution, obtaining what is known as the posterior distribution. This approach offers many advantages, allowing to intuitively integrate previous knowledge about relevant quantities into the data analysis, account for various systematic effects, and constrain the parameters to their physical values. All of these features are especially useful when dealing with a limited amount of data, as is the case for most neutrino experiments. A fully Bayesian treatment of complex problems is computationally expensive, since it requires to compute integrals of distributions over many dimensions. Because of this, algorithms such as Hamiltonian Monte Carlo (HMC), a variation of Markov Chain Monte Carlo, are employed to efficiently approximate these integrals by generating samples from the target distribution. The chapter describes several useful techniques for constructing and fitting statistical models using HMC. It also covers methods for testing the proper functioning of the algorithm, evaluating goodness of fit, and comparing different models. The theoretical descriptions of these methods are complemented by practical examples of their implementation in Stan.

Leveraging these tools, the last chapter presents some applications of Bayesian data analysis tailored to the Holmes experiment. At the first order, the calorimetric spectrum of <sup>163</sup>Ho consists of several Lorenzian-shaped peaks. The first part of the data analysis focuses on characterizing the peak closer to the endpoint. The main objectives at this stage are estimating the position of the peaks, assessing the influence of systematics in the energy calibration of the detectors and studying asymmetries in the lineshape due to higher order processes. The second part aims to estimate the expected sensitivity of Holmes to the neutrino mass in the near future, considering a simulated measurement with 64 detectors implanted with 1 Bq of <sup>163</sup>Ho each. This section focuses on studying the influence of priors and systematics on the obtained mass upper limit and how to provide a robust expected limit from simulated data. Another central and final aspect of this analysis is how to combine data from many detectors with different characteristics, such as energy resolution and calibration systematics, in order to make inferences on a common parameter, the neutrino mass.
